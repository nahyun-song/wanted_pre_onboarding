# Week1-4 과제 

##### 한국 스트리밍 서비스 (왓*, 쿠*플레이, 티*)에서 시청자가 영화를 보고 남긴 리뷰를 긍정과 부정으로 나누어 볼 수 있는 대시보드를 만들려고 한다. 
##### 리뷰 긍부정 판별 모델을 만들려고 할 때, NLP 리서처/엔지니어로서 어떤 의사 결정을 할 것인지 각 단계에 맞춰 작성해보자. 
##### (단, 수집된 리뷰 데이터의 개수가 1,000개 미만이라고 가정하자.)
-----

**문제 정의**

풀고자 하는 문제를 정의하세요. 

또한 데이터 생성 시 고려해야할 사항이 있다면 무엇인지 설명하세요. 

(예, 만약 긍정 리뷰가 부정 리뷰보다 많은 경우 어떻게 해야 할까?, 길이가 정말 긴 리뷰는 어떻게 전처리 해야 할까?)


✓ 풀고자 하는 문제
- 감정 분석이란?
    - 텍스트에 등장하는 단어들을 통해 어떤 감정이 드러나는지 분석하는 기법
    - 오피니언 마이닝으로도 불리며, 텍스트에 담긴 의견, 태도 등을 알아보는데 유용한 기법
    - 전이학습을 통해 리뷰를 감정분석하여 긍정적 리뷰인지 부정적 리뷰인지 판별
- 데이터 양의 부족 문제
    - 임의의 데이터에 대해서 정확도는 높이고 오버피팅은 줄이기 위해서 기본적으로 많은 양의 데이터를 이용하여 학습해야함
    - 데이터가 부족한 어려움을 해결하기 위해서 전이학습 진행

✓ 데이터 생성 시 고려해야할 사항
- 데이터 불균형 문제
- 긍정, 부정 분류가 모호한 단어는 어떻게 처리할 것인가
    ex) 놀랍다

---

**오픈 데이터 셋 및 벤치 마크 조사**

리뷰 긍부정 판별 모델에 사용할 수 있는 한국어 데이터 셋이 무엇이 있는지 찾아보고, 데이터 셋에 대한 설명과 링크를 정리하세요. 

추가적으로 영어 데이터셋도 있다면 정리하세요.


✓ 한국어 데이터셋
- 네이버 영화 리뷰 
    - https://www.kaggle.com/soohyun/naver-movie-review-dataset
    - id
    - document : 리뷰 - 텍스트 데이터
    - label : 0 - 부정 / 1 - 긍정
    - 훈련데이터 150,000개 / 테스트데이터 50,000개



✓ 영어 데이터셋
- IMDb Movie Reviews
    - https://ai.stanford.edu/~amaas/data/sentiment/
    - IMDB(Internet Movie Database)에서 추출한 50,000개의 리뷰로 구성된 이진 감정 분석 데이터 세트
    - 매우 양극화된 검토만을 고려
    - 부정적 리뷰는 10점 만점에 4점 이하, 긍정적 리뷰는 10점 만점에 7점 이상을 매김
    - 영화 한 편당 30편 이상의 리뷰가 수록되지 않는다
    - 데이터 집합에 레이블이 지정되지 않은 데이터가 추가로 포함되어 있다

---

**모델 조사**

Paperswithcode(https://paperswithcode.com/)에서 리뷰 긍부정 판별 모델로 사용할 수 있는 SOTA 모델을 찾아보고 SOTA 모델의 구조에 대해 간략하게 설명하세요. 

(모델 논문을 자세히 읽지 않아도 괜찮습니다. 키워드 중심으로 설명해 주세요.)

	
✓ NB-weighted-BON + dv-cosine
- 벡터 데이터에 대해 내적 대신 cosine similarity 사용하여 정확도를 향상시킴
- Accuracy : 97.4

---

**학습 방식**

**딥러닝 (Transfer Learning)**

사전 학습된 모델을 활용하는 (transfer - learning)방식으로 학습하려고 합니다. 이 때 학습 과정을 간략하게 서술해주세요. 

(예. 데이터 전처리 → 사전 학습된 모델을 00에서 가져옴 → …)

- 전이학습 : 큰 데이터셋을 사용해서 훈련된 모델
- 토크나이저 준비 -> 데이터 전처리 -> 업스트림 task 학습(pretrain) -> 다운스트림 task 학습(finetuning) -> 모델 출력값 만들고 후처리

---

**평가 방식**

긍부정 예측 task에서 주로 사용하는 평가 지표를 최소 4개 조사하고 설명하세요.

✓ 평가 지표
- F1 score
    - 정밀도와 재현율의 조화 평균
    - 정밀도와 재현율이 비슷한 분류기에서는 F1 점수가 높다 
        -> 항상 바람직하지만은 않음. 상황에 따라 정밀도가 중요할 수도 있고 재현율이 중요할 수도 있음
- Accuracy
    - 정확한 예측의 비율. 불균형한 데이터셋을 다룰 때는 사용하지 않는다
- Recall
    - 실제 positive인 것 중 올바르게 맞춘 것의 비율(분류기가 정확하게 감지한 양성 샘플의 비율)
- ROC_AUC
    - 정밀도에 대한 TPR의 곡선이 아니라 FPR에 대한 TPR의 곡선
    - FPR : 양성으로 잘못 분류된 음성 샘플의 비율 (1-TNR)
    - TPR(재현율) : 음성으로 정확하게 분류한 음성 샘플의 비율
    - 트레이드 오프 : 재현율(TPR)이 높을수록 분류기가 만드는 거짓 양성(FPR)이 늘어난다 (임계값을 낮춰 모두 True로 판단하게 하기 때문)
    - 최적의 임계값 : TPR은 최대화하고 FPR은 최소화하는 임계값
    - 좋은 분류기는 완전한 랜덤 분류기의 ROC 곡선에서 최대한 멀리 떨어져야 한다 (=왼쪽 위에 가까울 수록 좋은 분류기이다)
- AUC : 곡선 아래의 면적(area under the curve)
    - 여러 개의 분류기를 비교할 수 있음 (두 분류기의 ROC AUC 점수를 비교하여 어떤 분류기가 더 좋은 분류기인지 비교)
    - 완벽한 분류기 : 1
    - 완전한 랜덤 분류기 : 0.5
    - ROC곡선 vs. 정밀도/재현율(PR) 곡선
        - PR곡선 : 양성 클래스가 드물거나 거짓 음성보다 거짓 양성이 더 중요할 때 사용
        - ROC곡선 : 그 외




```python

```
